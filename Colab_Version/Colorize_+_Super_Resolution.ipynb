{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XowU5SANuMH8"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Nneji123/DeOldify.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "seVMiSKUuqNt"
      },
      "outputs": [],
      "source": [
        "!cd DeOldify/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "Cmp4-dsmui58",
        "outputId": "962b66b7-03dd-4690-a153-b104b3717d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.5\n",
            "    Uninstalling nest-asyncio-1.5.5:\n",
            "      Successfully uninstalled nest-asyncio-1.5.5\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 2.6.3\n",
            "    Uninstalling fastai-2.6.3:\n",
            "      Successfully uninstalled fastai-2.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "nbclient 0.6.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ISR-2.2.0 anyio-3.6.1 bottleneck-1.3.4 colabcode-0.1.2 fastai-1.0.51 fastapi-0.78.0 ffmpeg-python-0.2.0 gast-0.2.2 gunicorn-20.1.0 h11-0.13.0 h5py-2.10.0 keras-applications-1.0.8 nest-asyncio-1.4.3 nvidia-ml-py3-7.352.0 pyaml-21.10.1 pyngrok-5.1.0 python-multipart-0.0.5 sniffio-1.2.0 starlette-0.19.1 tensorboard-2.0.2 tensorboardX-1.6 tensorflow-2.0.0 tensorflow-estimator-2.0.1 typing-3.7.4.3 uvicorn-0.13.1 youtube-dl-2021.12.17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DeOldify/\")\n",
        "!pip install -r colab_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEic-RSQvKQK",
        "outputId": "91f31e1d-ba01-47f2-b0e7-c5934ebd9d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-19 13:16:50--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7247863 (6.9M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-v3-stable-linux-amd64.tgz.1’\n",
            "\n",
            "\r          ngrok-v3-   0%[                    ]       0  --.-KB/s               \rngrok-v3-stable-lin 100%[===================>]   6.91M  44.9MB/s    in 0.2s    \n",
            "\n",
            "2022-06-19 13:16:51 (44.9 MB/s) - ‘ngrok-v3-stable-linux-amd64.tgz.1’ saved [7247863/7247863]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xvzf ngrok-v3-stable-linux-amd64.tgz\n",
        "!ngrok authtoken 29vr8YhWZ9CDHrUq2kr0CpUA0e8_6ik4hU5GjJZeAYagTH5i4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /root/.torch/models\n",
        "!mkdir -p /content/DeOldify/models\n",
        "\n",
        "!wget -O /root/.torch/models/vgg16_bn-6c64b313.pth https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\n",
        "\n",
        "!wget -O /root/.torch/models/resnet34-333f7ec4.pth https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
        "\n",
        "!wget -O /content/DeOldify/models/ColorizeArtistic_gen.pth https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth\n",
        "!wget -O /content/DeOldify/models/ColorizeVideo_gen.pth https://data.deepai.org/deoldify/ColorizeVideo_gen.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V27rZ930FwIO",
        "outputId": "fa4bb5b1-cd09-4782-e814-d31f954585a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-19 13:16:52--  https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.32.208.46, 13.32.208.73, 13.32.208.88, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.32.208.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 553507836 (528M) [application/octet-stream]\n",
            "Saving to: ‘/root/.torch/models/vgg16_bn-6c64b313.pth’\n",
            "\n",
            "/root/.torch/models 100%[===================>] 527.87M  72.4MB/s    in 7.0s    \n",
            "\n",
            "2022-06-19 13:16:59 (75.1 MB/s) - ‘/root/.torch/models/vgg16_bn-6c64b313.pth’ saved [553507836/553507836]\n",
            "\n",
            "--2022-06-19 13:16:59--  https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.32.208.46, 13.32.208.73, 13.32.208.88, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.32.208.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87306240 (83M) [application/octet-stream]\n",
            "Saving to: ‘/root/.torch/models/resnet34-333f7ec4.pth’\n",
            "\n",
            "/root/.torch/models 100%[===================>]  83.26M  70.2MB/s    in 1.2s    \n",
            "\n",
            "2022-06-19 13:17:00 (70.2 MB/s) - ‘/root/.torch/models/resnet34-333f7ec4.pth’ saved [87306240/87306240]\n",
            "\n",
            "--2022-06-19 13:17:00--  https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255144681 (243M) [application/octet-stream]\n",
            "Saving to: ‘/content/DeOldify/models/ColorizeArtistic_gen.pth’\n",
            "\n",
            "/content/DeOldify/m 100%[===================>] 243.32M  31.7MB/s    in 8.1s    \n",
            "\n",
            "2022-06-19 13:17:09 (29.9 MB/s) - ‘/content/DeOldify/models/ColorizeArtistic_gen.pth’ saved [255144681/255144681]\n",
            "\n",
            "--2022-06-19 13:17:09--  https://data.deepai.org/deoldify/ColorizeVideo_gen.pth\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874066230 (834M) [application/octet-stream]\n",
            "Saving to: ‘/content/DeOldify/models/ColorizeVideo_gen.pth’\n",
            "\n",
            "/content/DeOldify/m 100%[===================>] 833.57M  32.1MB/s    in 27s     \n",
            "\n",
            "2022-06-19 13:17:37 (30.5 MB/s) - ‘/content/DeOldify/models/ColorizeVideo_gen.pth’ saved [874066230/874066230]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxQ5IkBXuoNj",
        "outputId": "6b2ba3e5-86d8-497f-b862-4d9e9a1fcf08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/DeOldify/\")\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile, Response\n",
        "from fastapi.responses import StreamingResponse, FileResponse\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "import torch\n",
        "import fastai\n",
        "from ISR.models import RDN\n",
        "from deoldify.visualize import *\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "rdn = RDN(weights='noise-cancel')\n",
        "\n",
        "colorizer = get_image_colorizer(artistic=True)\n",
        "\n",
        "\n",
        "@app.get('/')\n",
        "def home():\n",
        "    return {'Title': 'Super Resolution and Colorisation API'}\n",
        "\n",
        "\n",
        "# Endpoint for enhancing resolution and colorization of image\n",
        "@app.post(\"/enhance_and_colorise\")\n",
        "async def root(file: UploadFile = File(...)):\n",
        "\n",
        "    \n",
        "    contents = io.BytesIO(await file.read())\n",
        "    \n",
        "    file_bytes = np.asarray(bytearray(contents.read()), dtype=np.uint8)\n",
        "    \n",
        "    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR) \n",
        "    \n",
        "    cv2.imwrite(\"new.jpg\",img)\n",
        "    \n",
        "    sr_img = rdn.predict(img, by_patch_of_size=300)\n",
        "    \n",
        "    res, im_png = cv2.imencode(\".png\", sr_img)\n",
        "    \n",
        "    images = io.BytesIO(im_png.tobytes())\n",
        "\n",
        "    sr2_img = colorizer.get_transformed_image(images, render_factor=35)\n",
        "    \n",
        "    new_img = np.array(sr2_img)\n",
        "    # img = cv2.imdecode(np.array(sr_img), cv2.IMREAD_COLOR)\n",
        "    \n",
        "    res, im2_png = cv2.imencode(\".png\", new_img) \n",
        "\n",
        "    return StreamingResponse(io.BytesIO(im2_png.tobytes()), media_type=\"image/png\")\n",
        "\n",
        "\n",
        "# endpoint for just enhancing the image\n",
        "@app.post(\"/enhance\")\n",
        "async def root(file: UploadFile = File(...)):\n",
        "\n",
        "    # image = load_image_into_numpy_array(await file.read())\n",
        "\n",
        "    contents = io.BytesIO(await file.read())\n",
        "    file_bytes = np.asarray(bytearray(contents.read()), dtype=np.uint8)\n",
        "    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "    sr_img = rdn.predict(img, by_patch_of_size=300)\n",
        "\n",
        "    res, im_png = cv2.imencode(\".png\", sr_img)\n",
        "\n",
        "    return StreamingResponse(io.BytesIO(im_png.tobytes()), media_type=\"image/png\")\n",
        "\n",
        "# endpoint for just colorising the image\n",
        "# Please review this section I may have mixed up something\n",
        "@app.post(\"/colorise\")\n",
        "async def root(file: UploadFile = File(...)):\n",
        "\n",
        "    \n",
        "    contents = io.BytesIO(await file.read())\n",
        "    \n",
        "    file_bytes = np.asarray(bytearray(contents.read()), dtype=np.uint8)\n",
        "    \n",
        "    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR) \n",
        "    \n",
        "    cv2.imwrite(\"new.jpg\",img)\n",
        "    \n",
        "    #sr_img = rdn.predict(img, by_patch_of_size=300)\n",
        "    \n",
        "   # res, im_png = cv2.imencode(\".png\", sr_img)\n",
        "    \n",
        "    #images = io.BytesIO(im_png.tobytes())\n",
        "\n",
        "    sr2_img = colorizer.get_transformed_image(\"new.jpg\", render_factor=35)\n",
        "    \n",
        "    new_img = np.array(sr2_img)\n",
        "    # img = cv2.imdecode(np.array(sr_img), cv2.IMREAD_COLOR)\n",
        "    \n",
        "    res, im2_png = cv2.imencode(\".png\", new_img) \n",
        "\n",
        "    return StreamingResponse(io.BytesIO(im2_png.tobytes()), media_type=\"image/png\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGUNRnYsvKSz"
      },
      "outputs": [],
      "source": [
        "from colabcode import ColabCode\n",
        "cc = ColabCode(port=18000, code=False)\n",
        "cc.run_app(app=app)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Colorize_+_Super_Resolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}